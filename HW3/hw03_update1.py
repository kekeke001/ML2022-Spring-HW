# -*- coding: utf-8 -*-
"""HW03_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BPlwfKVoTfdRkImNr9XkUCEQeExwHAK-

# HW3 Image Classification
## We strongly recommend that you run with Kaggle for this homework

# Get Data
Notes: if the links are dead, you can download the data directly from Kaggle and upload it to the workspace, or you can use the Kaggle API to directly download the data into colab.
"""

! wget https://www.dropbox.com/s/6l2vcvxl54b0b6w/food11.zip

! unzip food11.zip

"""# Training"""

# Import necessary packages.
import numpy as np
import pandas as pd
import torch
import os
import torch.nn as nn
# torchvision.transforms 是 pytorch 中的图像预处理包，提供了常用的图像变换方式
import torchvision.transforms as transforms
# PIL (Python Image Library) 是 python 的第三方图像处理库，支持图像存储，显示和处理，能够处理几乎所有的图片格式。
# PIL.Image 模块在 sample code 中用于加载图像。
from PIL import Image
# "ConcatDataset" and "Subset" are possibly useful when doing semi-supervised learning.
from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset
from torchvision.datasets import DatasetFolder, VisionDataset

# This is for the progress bar.
from tqdm.auto import tqdm
import random

def same_seed(seed):
    '''Fixes random number generator seeds for reproducibility.'''
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

"""## **Transforms**
Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.

Please refer to PyTorch official website for details about different transforms.
"""

# Normally, We don't need augmentations in testing and validation.
# All we need here is to resize the PIL image and transform it into Tensor.
test_tfm = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

# However, it is also possible to use augmentation in the testing phase.
# You may use train_tfm to produce a variety of images and then test using ensemble methods
train_tfm = transforms.Compose([
    # Resize the image into a fixed shape (height = width = 128)
    transforms.Resize((128, 128)), # 调整图像大小，确保所有输入图像都具有相同的大小
    # 用于将 PIL 图像或 NumPy 数组转换为 PyTorch 张量。这个操作将图像数据转换为张量，并且将图像的像素值归一化到 [0, 1] 区间
    transforms.ToTensor(),
])

"""## **Datasets**
The data is labelled by the name, so we load images and label while calling '__getitem__'
"""

class FoodDataset(Dataset):

    def __init__(self,path,tfm=test_tfm,files = None):
        super(FoodDataset).__init__()
        self.path = path
        # os.listdir(path) 返回指定路径下的文件和文件夹列表
        # 获取指定路径下所有以 .jpg 结尾的文件，并将它们按字母顺序排序后保存在 self.files 列表中
        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(".jpg")])
        if files != None:
            self.files = files
        print(f"One {path} sample",self.files[0])
        self.transform = tfm

    def __len__(self):
        return len(self.files)

    # dataloader()在处理时会自动调用该函数
    # 学习一下这个方法！！
    def __getitem__(self,idx):
        fname = self.files[idx]
        # 对图像处理
        im = Image.open(fname)
        im = self.transform(im)
        #im = self.data[idx]
        try:
            label = int(fname.split("/")[-1].split("_")[0])
        # 捕获可能出现的异常
        except:
            label = -1 # test has no label
        return im,label

# "cuda" only when GPUs are available.
device = "cuda" if torch.cuda.is_available() else "cpu"

config = {
  'seed' : 6666,
  # The number of training epochs and patience.
  'n_epochs' : 50,
  'patience' : 300, # If no improvement in 'patience' epochs, early stop
  'batch_size' : 64, # 表示单次传递给程序用以训练的数据（样本）个数
  '_dataset_dir' : './food11',
  '_exp_name' : 'sample'
}

# Construct datasets.
# The argument "loader" tells how torchvision reads the data.
train_set = FoodDataset(os.path.join(config['_dataset_dir'],"training"), tfm=train_tfm)
train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True, num_workers=0, pin_memory=True)
valid_set = FoodDataset(os.path.join(config['_dataset_dir'],"validation"), tfm=test_tfm)
valid_loader = DataLoader(valid_set, batch_size=config['batch_size'], shuffle=True, num_workers=0, pin_memory=True)

class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        # torch.nn.MaxPool2d(kernel_size, stride, padding)
        # input 維度 [3, 128, 128]
        self.cnn = nn.Sequential(
            # padding参数为1，则会在原输入图像周围拓展一行一列，且填充数据默认为0
            # image size表示图像高和宽的像素
            # 输入通道数为 3，表示输入图像是彩色图像，具有 RGB 三个通道
            # 卷积核3*3
            # Conv2d(3, 64, 3, 1, 1)从输入通道3到输出通道64 --有64组卷积核，卷积核大小3x3
            # 提取特征，根据不同的卷积核，提取不同的特征-生成feature map
            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]
            # 将输入特征转换为均值为0，方差为1的数据 -- BN针对每个通道的相同的特征进行标准化操作
            # 可以确保在训练过程中每一层的输入数据都具有相对稳定的分布
            nn.BatchNorm2d(64),
            # ReLU函数的作用是在神经网络中引入非线性，从而使得神经网络能够学习和表示更加复杂的函数关系
            nn.ReLU(),
            # 池化核为2*2，stride为2，padding为0-不在周围进行填充
            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]

            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]

            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]

            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]

            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]
        )
        self.fc = nn.Sequential(
            nn.Linear(512*4*4, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 11)
        )

    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1) # out [512,16]
        # 返回一个11维向量，每个元素表示对应类别的概率
        return self.fc(out)

"""# Training"""

same_seed(config['seed'])

from torch.utils.tensorboard import SummaryWriter

def trainer(train_loader, val_loader, model, config, device):

  # For the classification task, we use cross-entropy as the measurement of performance.
  criterion = nn.CrossEntropyLoss()

  # Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.
  optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)

  # Writer of tensoboard.
  writer = SummaryWriter()


  # Initialize trackers, these are not parameters and should not be changed
  stale = 0
  best_acc = 0
  step = 0
  n_epochs = config['n_epochs']

  for epoch in range(config['n_epochs']):

      # ---------- Training ----------
      # Make sure the model is in train mode before training.
      model.train()

      # These are used to record information in training.
      train_loss = []
      train_accs = []

      train_pbar = tqdm(train_loader, position=0, leave=True)

      for batch in train_pbar:

          # A batch consists of image data and corresponding labels.
          imgs, labels = batch
          #imgs = imgs.half()
          # print(imgs.shape,labels.shape)

          # Forward the data. (Make sure data and model are on the same device.)
          logits = model(imgs.to(device))

          # Calculate the cross-entropy loss.
          # We don't need to apply softmax before computing cross-entropy as it is done automatically.
          loss = criterion(logits, labels.to(device))

          # Gradients stored in the parameters in the previous step should be cleared out first.
          optimizer.zero_grad()

          # Compute the gradients for parameters.
          loss.backward()

          # Clip the gradient norms for stable training
          # 解决梯度爆炸的问题
          grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)

          # Update the parameters with computed gradients.
          optimizer.step()
          step += 1

          # Compute the accuracy for current batch.
          # argmax(dim=-1) 返回最后一个维度的最大值下标
          acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()

          # Record the loss and accuracy.
          train_loss.append(loss.item())
          train_accs.append(acc)

           # 设置进度条信息
          train_pbar.set_description(f'Epoch [{epoch + 1}/{n_epochs}]')
          train_pbar.set_postfix({'train_loss': loss.detach().item()})

      train_loss = sum(train_loss) / len(train_loss)
      train_acc = sum(train_accs) / len(train_accs)
      # 每隔num_batch个step记录一次
      writer.add_scalar('Loss/train', train_loss, step)

      # Print the information.
      print(f"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}")

      # ---------- Validation ----------
      # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.
      model.eval()

      # These are used to record information in validation.
      valid_loss = []
      valid_accs = []

      # Iterate the validation set by batches.

      valid_pbar = tqdm(valid_loader, position=0, leave=True)

      for batch in valid_pbar:

          # A batch consists of image data and corresponding labels.
          imgs, labels = batch
          #imgs = imgs.half()

          # We don't need gradient in validation.
          # Using torch.no_grad() accelerates the forward process.
          with torch.no_grad():
              logits = model(imgs.to(device))

          # We can still compute the loss (but not the gradient).
          loss = criterion(logits, labels.to(device))

          # Compute the accuracy for current batch.
          acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()
          # Record the loss and accuracy.
          valid_loss.append(loss.item())
          valid_accs.append(acc)
          #break
           # 设置进度条信息
          valid_pbar.set_description(f'Epoch [{epoch + 1}/{n_epochs}]')
          valid_pbar.set_postfix({'valid_loss': loss.detach().item()})

      # The average loss and accuracy for entire validation set is the average of the recorded values.
      valid_loss = sum(valid_loss) / len(valid_loss)
      valid_acc = sum(valid_accs) / len(valid_accs)
      writer.add_scalar('Loss/valid', valid_loss, step)
      # Print the information.
      print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")


      # update logs
      if valid_acc > best_acc:
          with open(f"./{config['_exp_name']}_log.txt","a"):
            # "a"表示追加写入
              print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best")
      else:
          with open(f"./{config['_exp_name']}_log.txt","a"):
              print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")


      # save models
      if valid_acc > best_acc:
          print(f"Best model found at epoch {epoch}, saving model")
          torch.save(model.state_dict(), f"{config['_exp_name']}_best.ckpt") # only save best to prevent output memory exceed error
          best_acc = valid_acc
          stale = 0
      else:
          stale += 1
          if stale > config['patience']:
              print(f"No improvment {config['patience']} consecutive epochs, early stopping")
              break

  # Initialize a model, and put it on the device specified.
model = Classifier().to(device)
trainer(train_loader, valid_loader, model, config, device)

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard
# %tensorboard --logdir=./runs/

test_set = FoodDataset(os.path.join(_dataset_dir,"test"), tfm=test_tfm)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)

"""# Testing and generate prediction CSV"""

model_best.load_state_dict(torch.load(f"{config['_exp_name']}_best.ckpt"))
model_best.eval()
prediction = []
with torch.no_grad():
    for data,_ in test_loader:
        test_pred = model_best(data.to(device))
        print("test_pred",test_pred.shape)
        # squeeze() 方法会去除数组中的单维度，将其压缩为一维数组
        # tolist() 方法将 NumPy 数组转换为 Python 列表。
        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)
        print("test_label",test_label.shape)
        prediction += test_label.squeeze().tolist()
        print("test_prediction",prediction.shape)

#create test csv
#  定义一个函数，用于将整数转换为长度为 4 的字符串，不足的部分用零填充-- 1 --> 0001,用于表示id
def pad4(i):
    return "0"*(4-len(str(i)))+str(i)
df = pd.DataFrame()
df["Id"] = [pad4(i) for i in range(1,len(test_set)+1)]
df["Category"] = prediction
# 将 DataFrame 中的数据保存为 CSV 文件，不保存行索引
df.to_csv("submission.csv",index = False)

"""# Q1. Augmentation Implementation
## Implement augmentation by finishing train_tfm in the code with image size of your choice.
## Directly copy the following block and paste it on GradeScope after you finish the code
### Your train_tfm must be capable of producing 5+ different results when given an identical image multiple times.
### Your  train_tfm in the report can be different from train_tfm in your training code.

"""

train_tfm = transforms.Compose([
    # Resize the image into a fixed shape (height = width = 128)
    transforms.Resize((128, 128)),
    # You need to add some transforms here.
    transforms.ToTensor(),
])

"""# Q2. Residual Implementation
![](https://i.imgur.com/GYsq1Ap.png)
## Directly copy the following block and paste it on GradeScope after you finish the code

"""

from torch import nn
class Residual_Network(nn.Module):
    def __init__(self):
        super(Residual_Network, self).__init__()

        self.cnn_layer1 = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1),
            nn.BatchNorm2d(64),
        )

        self.cnn_layer2 = nn.Sequential(
            nn.Conv2d(64, 64, 3, 1, 1),
            nn.BatchNorm2d(64),
        )

        self.cnn_layer3 = nn.Sequential(
            nn.Conv2d(64, 128, 3, 2, 1),
            nn.BatchNorm2d(128),
        )

        self.cnn_layer4 = nn.Sequential(
            nn.Conv2d(128, 128, 3, 1, 1),
            nn.BatchNorm2d(128),
        )
        self.cnn_layer5 = nn.Sequential(
            nn.Conv2d(128, 256, 3, 2, 1),
            nn.BatchNorm2d(256),
        )
        self.cnn_layer6 = nn.Sequential(
            nn.Conv2d(256, 256, 3, 1, 1),
            nn.BatchNorm2d(256),
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(256* 32* 32, 256),
            nn.ReLU(),
            nn.Linear(256, 11)
        )
        self.relu = nn.ReLU()

    def forward(self, x):
        # input (x): [batch_size, 3, 128, 128]
        # output: [batch_size, 11]

        # Extract features by convolutional layers.
        x1 = self.cnn_layer1(x)

        x1 = self.relu(x1)

        x2 = self.cnn_layer2(x1)

        x2 = self.relu(x2)

        x3 = self.cnn_layer3(x2)

        x3 = self.relu(x3)

        x4 = self.cnn_layer4(x3)

        x4 = self.relu(x4)

        x5 = self.cnn_layer5(x4)

        x5 = self.relu(x5)

        x6 = self.cnn_layer6(x5)

        x6 = self.relu(x6)

        # The extracted feature map must be flatten before going to fully-connected layers.
        # 将x6按第一维度展平，为了后面的fc运算
        xout = x6.flatten(1)

        # The features are transformed by fully-connected layers to obtain the final logits.
        xout = self.fc_layer(xout)
        return xout