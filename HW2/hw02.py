# -*- coding: utf-8 -*-
"""HW02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/kekeke001/ML2022-Spring-HW/blob/main/HW02.ipynb

# **Homework 2 Phoneme Classification**

* Slides: https://docs.google.com/presentation/d/1v6HkBWiJb8WNDcJ9_-2kwVstxUWml87b9CnA16Gdoio/edit?usp=sharing
* Kaggle: https://www.kaggle.com/c/ml2022spring-hw2
* Video: TBA
"""

!nvidia-smi

"""## Download Data
Download data from google drive, then unzip it.

You should have
- `libriphone/train_split.txt`
- `libriphone/train_labels`
- `libriphone/test_split.txt`
- `libriphone/feat/train/*.pt`: training feature<br>
- `libriphone/feat/test/*.pt`:  testing feature<br>

after running the following block.

> **Notes: if the links are dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2022spring-hw2/data) and upload it to the workspace, or you can use [the Kaggle API](https://www.kaggle.com/general/74235) to directly download the data into colab.**

### Download train/test metadata
"""

# Main link
!wget -O libriphone.zip "https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip"

# Backup Link 0
# !pip install --upgrade gdown
# !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip

# Backup link 1
# !pip install --upgrade gdown
# !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip

# Backup link 2
# !wget -O libriphone.zip "https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1"

# Backup link 3
# !wget -O libriphone.zip "https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1"

!unzip -q libriphone.zip
!ls libriphone

"""### Preparing Data

**Helper functions to pre-process the training data from raw MFCC features of each utterance.**

A phoneme may span several frames and is dependent to past and future frames. \
Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.

Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)
"""

import os
import random
import pandas as pd
import torch
from tqdm import tqdm

def load_feat(path):
    feat = torch.load(path)
    return feat

def shift(x, n):
    if n < 0:
        left = x[0].repeat(-n, 1)
        right = x[:n]

    elif n > 0:
        right = x[-1].repeat(n, 1)
        left = x[n:]
    else:
        return x

    return torch.cat((left, right), dim=0)

# 此方法非常巧妙！！！
def concat_feat(x, concat_n):
    # concat_n一定得是奇数
    # 以每个frame为中心，扩展了concat_nframes个邻近frame的向量。如果一个frame在边缘，则以他自身代替邻近frame进行扩展
    assert concat_n % 2 == 1
    if concat_n < 2:
        return x
    seq_len, feature_dim = x.size(0), x.size(1)
    # 行保存不变，列维度重复 concat_n 次
    x = x.repeat(1, concat_n)
    # x.view(seq_len, concat_n, feature_dim)：这一步将张量 x 的形状变换为 (seq_len, concat_n, feature_dim)
    # permute：这一步对张量进行维度重排--concat_n, seq_len, feature_dim
    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2)
    mid = (concat_n // 2)
    for r_idx in range(1, mid+1):
        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)
        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)

    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)

def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):
    # 一共有41种分类
    class_num = 41 # NOTE: pre-computed, should not need change
    mode = 'train' if (split == 'train' or split == 'val') else 'test'

    # label的处理
    label_dict = {}
    if mode != 'test':
      # os.path.join --路径拼接
      # .readlines() --一次性读取所有的行
      # phone_file：列表形式 ['line 1\n'、'line 2\n' 和 'line 3\n']
      phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()
      # 逐行读取phone_file文件
      for line in phone_file:
          # 使用 strip() 方法去除每行末尾的换行符
          # split(' ') 方法根据空格字符将每行文本分割成多个单词，返回一个包含这些单词的列表
          line = line.strip('\n').split(' ')
          # label：字典 {audio_fea:[label]}
          label_dict[line[0]] = [int(p) for p in line[1:]]

    # split training and validation data
    if split == 'train' or split == 'val':
        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()
        random.seed(train_val_seed)
        # shuffle() 函数将随机地打乱列表中的元素的顺序，该函数不返回任何值
        random.shuffle(usage_list)
        # 训练集的划分--训练集+验证集
        percent = int(len(usage_list) * train_ratio)
        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]
    elif split == 'test':
        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()
    else:
        raise ValueError('Invalid \'split\' argument for dataset: PhoneDataset!')

    usage_list = [line.strip('\n') for line in usage_list]
    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))

    # 将所有feat整合到一个X中，所对应的label整合到一个y中
    max_len = 3000000
    X = torch.empty(max_len, 39 * concat_nframes)
    if mode != 'test':
      y = torch.empty(max_len, dtype=torch.long)

    idx = 0
    for i, fname in tqdm(enumerate(usage_list)):
        # 注意对不同文件格式的操作
        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))
        cur_len = len(feat)
        # 考虑到周围的feat的影响,一个.pt文件里其实有多个frame,每行是一个frame
        # 以每个frame为中心，扩展了concat_nframes个邻近frame的向量。如果一个frame在边缘，则以他自身代替邻近frame进行扩展
        feat = concat_feat(feat, concat_nframes)
        if mode != 'test':
          label = torch.LongTensor(label_dict[fname])

        X[idx: idx + cur_len, :] = feat
        if mode != 'test':
          y[idx: idx + cur_len] = label

        idx += cur_len

    X = X[:idx, :]
    if mode != 'test':
      y = y[:idx]

    print(f'[INFO] {split} set')
    # X:(num_frame,39*n_frame)
    print(X.shape)
    if mode != 'test':
      # y:(num_frame,)
      print(y.shape)
      return X, y
    else:
      return X

"""## Define Dataset"""

import torch
from torch.utils.data import Dataset
from torch.utils.data import DataLoader

class LibriDataset(Dataset):
    def __init__(self, X, y=None):
        self.data = X
        if y is not None:
            self.label = torch.LongTensor(y)
        else:
            self.label = None

    def __getitem__(self, idx):
        if self.label is not None:
            return self.data[idx], self.label[idx]
        else:
            return self.data[idx]

    def __len__(self):
        return len(self.data)

"""## Define Model"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class BasicBlock(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(BasicBlock, self).__init__()

        self.block = nn.Sequential(
            nn.Linear(input_dim, output_dim),
            nn.ReLU(),
        )

    def forward(self, x):
        x = self.block(x)
        return x


class Classifier(nn.Module):
    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):
        super(Classifier, self).__init__()

        self.fc = nn.Sequential(
            BasicBlock(input_dim, hidden_dim),
            # hidden_layers个BasicBlock(hidden_dim, hidden_dim)
            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],
            # 这个输出是41维度的
            nn.Linear(hidden_dim, output_dim)
        )

    # 对父类的forward进行重写
    def forward(self, x):
        x = self.fc(x)
        return x

"""## Hyper-parameters"""

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
config = {
  # data prarameters
  'concat_nframes' : 1,           # the number of frames to concat with, n must be odd (total 2k+1 = n frames)
  'train_ratio': 0.8,               # the ratio of data used for training, the rest will be used for validation

  # training parameters
  'seed':0,                        # random seed
  'batch_size':1024,              # batch size
  'num_epoch': 10,                 # the number of training epoch
  'learning_rate':0.0001,       # learning rate
  'model_path':'./models/model.ckpt' ,    # the path where the checkpoint will be saved

  # model parameters
  'input_dim': 39 * 'concat_nframes' , # the input dim of the model, you should not change the value
  'hidden_layers' : 1,              # the number of hidden layers
  'hidden_dim' : 256                # the hidden dim
}

"""## Prepare dataset and model"""

import gc

# preprocess data
train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=config['concat_nframes'], train_ratio=config['train_ratio'])
val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=config['concat_nframes'], train_ratio=config['train_ratio'])

# get dataset
train_set = LibriDataset(train_X, train_y)
val_set = LibriDataset(val_X, val_y)

# 去掉不用的东西节省空间
# del删除的是变量，而不是数据
del train_X, train_y, val_X, val_y
gc.collect() # 垃圾回收

# get dataloader
train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)
val_loader = DataLoader(val_set, batch_size=config['batch_size'], shuffle=False)



import numpy as np

#fix seed
def same_seeds(seed):
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True



"""## Training"""

# For plotting learning curve
from torch.utils.tensorboard import SummaryWriter

def trainer(train_loader, val_loader, model, config, device):
    # 在PyTorch中，nn.CrossEntropyLoss() 函数会自动对模型的输出进行 softmax 操作，因此在传入 output 时，不需要手动进行 softmax 处理

    criterion = nn.CrossEntropyLoss()

    # 优化器
    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])

     # Writer of tensoboard.
    writer = SummaryWriter()

    # Create directory of saving models.
    if not os.path.isdir('./models'):
        os.mkdir('./models')

    best_acc = 0.0
    n_epochs = config['num_epoch']
    step = 0
    for epoch in range(n_epochs):
        train_acc = 0.0
        train_loss = 0.0
        val_acc = 0.0
        val_loss = 0.0
        loss_record = []

        # training
        model.train()  # set the model to training mode
        # tqdm is a package to visualize your training progress.
        train_pbar = tqdm(train_loader, position=0, leave=True)

        for features, labels in train_pbar:
            features = features.to(device)
            labels = labels.to(device)
            # 梯度设置为0
            optimizer.zero_grad()
            outputs = model(features)
            # nn.CrossEntropyLoss() 函数会自动对模型的输出进行 softmax 操作
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            step += 1
            loss_record.append(loss.detach().item())

            # 返回每个frame的预测概率值最大的值及其索引--即返回其分类
            _, train_pred = torch.max(outputs, 1)
            train_acc += (train_pred.detach() == labels.detach()).sum().item()
            train_loss += loss.item()

            # 设置进度条信息
            train_pbar.set_description(f'Epoch [{epoch + 1}/{n_epochs}]')
            train_pbar.set_postfix({'train_loss': loss.detach().item()})

        avg_train_acc = train_acc / len(train_set)
        avg_train_loss = train_loss / len(loss_record)
        # 每隔num_batch个step记录一次
        writer.add_scalar('Loss/train', avg_train_loss, step)

        # validation
        if len(val_set) > 0:
            model.eval()  # set the model to evaluation mode
            loss_record = []
            val_pbar = tqdm(val_loader, position=0, leave=True)
            with torch.no_grad():
                for features, labels in val_pbar:
                    features = features.to(device)
                    labels = labels.to(device)
                    outputs = model(features)

                    loss = criterion(outputs, labels)
                    loss_record.append(loss.detach().item())
                    _, val_pred = torch.max(outputs, 1)
                    val_acc += (
                                val_pred.cpu() == labels.cpu()).sum().item()  # get the index of the class with the highest probability
                    val_loss += loss.item()

                    # 设置进度条信息
                    val_pbar.set_description(f'Epoch [{epoch + 1}/{n_epochs}]')
                    val_pbar.set_postfix({'val_loss': loss.detach().item()})

                avg_val_acc = val_acc / len(val_set)
                avg_val_loss = val_loss / len(val_loader)
                writer.add_scalar('Loss/valid', avg_val_loss, step)

                print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(
                epoch + 1, n_epochs, avg_train_acc, avg_train_loss, avg_val_acc, avg_val_loss
            ))

            # if the model improves, save a checkpoint at this epoch
            if val_acc > best_acc:
                best_acc = val_acc
                torch.save(model.state_dict(), config['model_path']) # Save your best model
                print('saving model with acc {:.3f}'.format(best_acc / len(val_set)))
    else:
        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(
            epoch + 1, n_epochs, avg_train_acc, avg_train_loss)
        )


    # if not validating, save the last epoch
    if len(val_set) == 0:
        torch.save(model.state_dict(), config['model_path'])
        print('saving model at last epoch')

model = Classifier(input_dim=39, hidden_layers=config['hidden_layers'], hidden_dim=config['hidden_dim']).to(device)
trainer(train_loader, val_loader, model, config, device)

del train_loader, val_loader
gc.collect()

"""## Testing
Create a testing dataset, and load model from the saved checkpoint.
"""

# load data
test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=config['concat_nframes'])
test_set = LibriDataset(test_X, None)
test_loader = DataLoader(test_set, batch_size=config['batch_size'], shuffle=False)

# create model, define a loss function, and optimizer
model.load_state_dict(torch.load(config['model_path']))

"""# Plot learning curves with tensorboard
tensorboard is a tool that allows you to visualize your training progress.

If this block does not display your learning curve, please wait for few minutes, and re-run this block. It might take some time to load your logging information.
"""

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard
# %tensorboard --logdir=./runs/

"""Make prediction."""

test_acc = 0.0
test_lengths = 0
pred = np.array([], dtype=np.int32)

model.eval()
test_pbar = tqdm(test_loader, position=0, leave=True)
with torch.no_grad():
    for features in test_pbar:
        features = features.to(device)

        outputs = model(features)

        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability
        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)

"""Write prediction to a CSV file.

After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle.
"""

with open('prediction.csv', 'w') as f:
    f.write('Id,Class\n')
    for i, y in enumerate(pred):
        f.write('{},{}\n'.format(i, y))